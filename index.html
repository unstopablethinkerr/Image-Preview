      <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Surface Tracking with OpenCV.js</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: black;
      height: 100%;
      width: 100%;
    }
    #video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      z-index: 1;
    }
    #overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: 2;
    }
    #controls {
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0,0,0,0.6);
      padding: 10px;
      border-radius: 10px;
      z-index: 4;
      color: white;
      text-align: center;
    }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline></video>
  <canvas id="overlay"></canvas>

  <div id="controls">
    <input type="file" id="imageUpload" accept="image/*"><br>
    <button id="debugToggle">Toggle Debug</button>
  </div>

  <!-- OpenCV.js -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>

  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    let debugMode = true;
    let uploadedImg = null;

    // Start camera
    navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } })
      .then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          overlay.width = video.videoWidth;
          overlay.height = video.videoHeight;
        };
      });

    // Handle image upload
    document.getElementById('imageUpload').addEventListener('change', (event) => {
      const file = event.target.files[0];
      if (file) {
        const img = new Image();
        img.onload = () => { uploadedImg = img; };
        img.src = URL.createObjectURL(file);
      }
    });

    // Toggle debug mode
    document.getElementById('debugToggle').addEventListener('click', () => {
      debugMode = !debugMode;
    });

    function onOpenCvReady() {
      console.log("OpenCV.js ready");

      const cap = new cv.VideoCapture(video);
      const src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
      const gray = new cv.Mat();
      const edges = new cv.Mat();
      const contours = new cv.MatVector();
      const hierarchy = new cv.Mat();

      function processFrame() {
        if (video.readyState === video.HAVE_ENOUGH_DATA) {
          cap.read(src);
          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
          cv.GaussianBlur(gray, gray, new cv.Size(5, 5), 0);
          cv.Canny(gray, edges, 75, 200);

          // Find contours
          cv.findContours(edges, contours, hierarchy, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE);
          ctx.drawImage(video, 0, 0, overlay.width, overlay.height);

          let biggestQuad = null;
          for (let i = 0; i < contours.size(); i++) {
            const cnt = contours.get(i);
            const peri = cv.arcLength(cnt, true);
            const approx = new cv.Mat();
            cv.approxPolyDP(cnt, approx, 0.02 * peri, true);

            if (approx.rows === 4) {
              const pts = [];
              for (let j = 0; j < 4; j++) {
                pts.push({
                  x: approx.intAt(j, 0),
                  y: approx.intAt(j, 1)
                });
              }
              if (!biggestQuad || cv.contourArea(cnt) > cv.contourArea(biggestQuad)) {
                biggestQuad = pts;
              }
            }
            approx.delete();
          }

          // Draw debug contours
          if (debugMode) {
            ctx.strokeStyle = "lime";
            ctx.lineWidth = 2;
            for (let i = 0; i < contours.size(); i++) {
              const cnt = contours.get(i);
              ctx.beginPath();
              for (let j = 0; j < cnt.data32S.length; j += 2) {
                const x = cnt.data32S[j];
                const y = cnt.data32S[j + 1];
                if (j === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
              }
              ctx.closePath();
              ctx.stroke();
            }
          }

          // If quad found, warp and overlay image
          if (biggestQuad && uploadedImg) {
            const srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
              0, 0,
              uploadedImg.width, 0,
              uploadedImg.width, uploadedImg.height,
              0, uploadedImg.height
            ]);

            const dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
              biggestQuad[0].x, biggestQuad[0].y,
              biggestQuad[1].x, biggestQuad[1].y,
              biggestQuad[2].x, biggestQuad[2].y,
              biggestQuad[3].x, biggestQuad[3].y
            ]);

            const M = cv.getPerspectiveTransform(srcTri, dstTri);
            const dsize = new cv.Size(overlay.width, overlay.height);
            const warped = new cv.Mat();
            cv.warpPerspective(cv.imread(uploadedImg), warped, M, dsize);

            // Overlay
            const warpedCanvas = document.createElement("canvas");
            warpedCanvas.width = warped.cols;
            warpedCanvas.height = warped.rows;
            cv.imshow(warpedCanvas, warped);
            ctx.drawImage(warpedCanvas, 0, 0);

            warped.delete(); M.delete(); srcTri.delete(); dstTri.delete();
          }
        }
        requestAnimationFrame(processFrame);
      }
      requestAnimationFrame(processFrame);
    }
  </script>
</body>
</html>
